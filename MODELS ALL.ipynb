{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import utils\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# import importlib\n",
    "# utils = importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loo = pd.read_csv('loo.csv', sep=';', header=None)\n",
    "# loo.columns=['loo']\n",
    "# loo['target']=y_train\n",
    "# loo_loss = loo.apply(lambda x: log_loss([x['target']], [x['loo']], labels=[1, 0]), axis=1)\n",
    "# pd.DataFrame(loo_loss).to_csv('loo_loss.csv', index=False, header=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from utils import SmoothLikelihood,SmoothLikelihood2,SmoothLikelihood3,SmoothLikelihood4, ColumnsFilter\n",
    "\n",
    "def wrap_classifier(clf, use_columns, mean_columns):\n",
    "    fs = [(\"filter\", ColumnsFilter(use_columns))]\n",
    "    \n",
    "    for i, cc in enumerate(mean_columns):\n",
    "        fs.append(('mean_'+str(i), SmoothLikelihood4(cc, 0.5,\n",
    "                                                     kf=StratifiedKFold(random_state=111111+i, n_splits=20, shuffle=True),\n",
    "                                                     alpha=13,\n",
    "                                                     seed=10+i,\n",
    "                                                     std=0.0013)))\n",
    "    combined_features = FeatureUnion(fs)\n",
    "    return Pipeline([(\"features\", combined_features), (\"model\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep=';')\n",
    "test = pd.read_csv('test.csv', sep=';', na_values='None')\n",
    "\n",
    "train = utils.clean_data(train)\n",
    "test = utils.clean_data(test)\n",
    "\n",
    "train = utils.new_features(train)\n",
    "test = utils.new_features(test)\n",
    "\n",
    "X_train = train.drop([ 'cardio'], axis=1)\n",
    "y_train = train['cardio'].values.ravel()\n",
    "X_test = test.drop([], axis=1)\n",
    "\n",
    "# ccc = ['age', 'age_group', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'BMI', 'MAP']\n",
    "# def new_cols(data):    \n",
    "#     for col1 in ccc:\n",
    "#         data[col1 + '_log'] = np.log(data[col1] + 1.1)\n",
    "#         for col2 in ccc:\n",
    "#             data['%s_mul_%s' % (col1, col2)] = data[col1] * data[col2]\n",
    "#             data['%s_mul_log_%s' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
    "#             data['%s_div_log_%s' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 1)\n",
    "\n",
    "#             if col2 == col1:\n",
    "#                 continue\n",
    "\n",
    "#             data['%s_div_%s' % (col1, col2)] = data[col1] / (data[col2] + 1)\n",
    "\n",
    "# new_cols(X_train)\n",
    "# new_cols(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loo_loss = pd.read_csv('loo_loss.csv', sep=';', header=None)\n",
    "strat = pd.qcut(loo_loss, 20, labels=False).astype(str)\n",
    "strat = np.hstack((strat, y_train.reshape((-1,1))))\n",
    "strat =np.apply_along_axis(lambda d: str(d[0]) + '_' + str(d[1]), 1, strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_columns = [\n",
    "\"gender\",\n",
    "\"height\",\n",
    "\"weight\",\n",
    "\"ap_hi\",\n",
    "\"ap_lo\",\n",
    "\"cholesterol\",\n",
    "# \"gluc\",\n",
    "\"active_fair\",\n",
    "\"smoke_restored\",\n",
    "\"alco_restored\",\n",
    "# \"active_restored\",\n",
    "\"height_mul_log_gluc\",\n",
    "\"BMI\",\n",
    "\"age_group\",\n",
    "\"cholesterol_div_log_gluc\",\n",
    "\"gluc_mul_log_age\",\n",
    "]\n",
    "mean_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'XGB_1'\n",
    "params = {\n",
    "     'colsample_bytree': 0.875,\n",
    "     'gamma': 0.05,\n",
    "     'learning_rate': 0.02,\n",
    "     'max_depth': 5,\n",
    "     'min_child_weight': 5,\n",
    "     'n_estimators': 369,\n",
    "\n",
    "     'reg_alpha': 0,\n",
    "     'reg_lambda': 10,\n",
    "     'subsample': 0.7,\n",
    "    \n",
    "    'n_jobs': 1,\n",
    "    'random_state': 1111,\n",
    "    'silent': True,\n",
    "}\n",
    "model = wrap_classifier(xgb.XGBClassifier(**params), use_columns, mean_columns)\n",
    "utils.execute_model(model,\n",
    "              X_train,\n",
    "              y_train,\n",
    "              X_test,\n",
    "              model_name=model_name,\n",
    "              n_splits=15,\n",
    "              n_folds=10,\n",
    "              stratification_groups=strat,\n",
    "             )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'XGB_2hist'\n",
    "params = {\n",
    "     'colsample_bytree': 0.95,\n",
    "     'gamma': 0.55,\n",
    "     'learning_rate': 0.02,\n",
    "     'max_depth': 5,\n",
    "     'min_child_weight': 3,\n",
    "     'n_estimators': 392,\n",
    "     'reg_alpha': 0,\n",
    "     'reg_lambda': 0.4,\n",
    "     'subsample': 0.85,\n",
    "\n",
    "    'tree_method': 'hist',\n",
    "    'grow_policy': 'lossguide',\n",
    "    \n",
    "    'n_jobs': 4,\n",
    "    'random_state': 2222,\n",
    "    'silent': True,\n",
    "}\n",
    "model = wrap_classifier(xgb.XGBClassifier(**params), use_columns, mean_columns)\n",
    "utils.execute_model(model,\n",
    "              X_train,\n",
    "              y_train,\n",
    "              X_test,\n",
    "              model_name=model_name,\n",
    "              n_splits=15,\n",
    "              n_folds=10,\n",
    "              stratification_groups=strat,\n",
    "             )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'XGB_3hist'\n",
    "clf = xgb.XGBClassifier(\n",
    "        learning_rate=0.07,\n",
    "        n_estimators=218,\n",
    "        max_depth=3,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.2,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.55,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=1.0,\n",
    "        nthread=4,\n",
    "        tree_method='hist',\n",
    "        grow_policy='lossguide',\n",
    "       \n",
    "        seed=3333\n",
    "    )\n",
    "model = wrap_classifier(clf, use_columns, mean_columns)\n",
    "utils.execute_model(model,\n",
    "              X_train,\n",
    "              y_train,\n",
    "              X_test,\n",
    "              model_name=model_name,\n",
    "              n_splits=15,\n",
    "              n_folds=10,\n",
    "              stratification_groups=strat,\n",
    "             )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'XGB_4'\n",
    "clf = xgb.XGBClassifier(\n",
    "        learning_rate=0.06,\n",
    "        n_estimators=114,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.3,\n",
    "        subsample=0.5,\n",
    "        colsample_bytree=0.5,\n",
    "        reg_alpha=9,\n",
    "        reg_lambda=1.4,\n",
    "        nthread=4,\n",
    "       \n",
    "        seed=4444\n",
    "    )\n",
    "model = wrap_classifier(clf, use_columns, mean_columns)\n",
    "utils.execute_model(model,\n",
    "              X_train,\n",
    "              y_train,\n",
    "              X_test,\n",
    "              model_name=model_name,\n",
    "              n_splits=15,\n",
    "              n_folds=10,\n",
    "              stratification_groups=strat,\n",
    "             )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'LGB_1'\n",
    "params = {\n",
    "     'colsample_bytree': 0.95,\n",
    "     'learning_rate': 0.02,\n",
    "#      'max_depth': 5,\n",
    "     'num_leaves': 2**5,\n",
    "     'min_child_weight': 3,\n",
    "     'n_estimators': 392,\n",
    "     'reg_alpha': 0,\n",
    "     'reg_lambda': 0.4,\n",
    "     'subsample': 0.85,\n",
    "       \n",
    "    'nthread': 4,\n",
    "    'seed': 8718,\n",
    "    'silent': True,\n",
    "}\n",
    "model = wrap_classifier(lgb.LGBMClassifier(**params), use_columns, mean_columns)\n",
    "utils.execute_model(model,\n",
    "              X_train,\n",
    "              y_train,\n",
    "              X_test,\n",
    "              model_name=model_name,\n",
    "              n_splits=15,\n",
    "              n_folds=10,\n",
    "              stratification_groups=strat,\n",
    "             )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'LGB_2'\n",
    "clf = lgb.LGBMClassifier(\n",
    "        learning_rate=0.07,\n",
    "        n_estimators=218,\n",
    "#         max_depth=3,\n",
    "        num_leaves=2**3,\n",
    "        min_child_weight=5,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.55,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=1.0,\n",
    "        nthread=4,\n",
    "       \n",
    "        seed=2222\n",
    "    )\n",
    "model = wrap_classifier(clf, use_columns, mean_columns)\n",
    "utils.execute_model(model,\n",
    "              X_train,\n",
    "              y_train,\n",
    "              X_test,\n",
    "              model_name=model_name,\n",
    "              n_splits=15,\n",
    "              n_folds=10,\n",
    "              stratification_groups=strat,\n",
    "             )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adamax\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class KerasModel(object):\n",
    "    def __init__(self,\n",
    "                 var_num,\n",
    "                 epochs=70,\n",
    "                 learn_rate=0.1,\n",
    "                 config=None,\n",
    "                 batch_size=512,\n",
    "                 verbose=0,\n",
    "                 validation_split=0.2,\n",
    "                 loss=\"binary_crossentropy\"):\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.validation_split = validation_split\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        model = self.model\n",
    "        \n",
    "        if config is None:\n",
    "            config =[(var_num, 0.0)]\n",
    "        else:\n",
    "            config = config.copy()\n",
    "            \n",
    "        n, dp = config.pop(0)\n",
    "\n",
    "        model.add(Dense(n, input_dim=var_num, kernel_initializer='uniform'))\n",
    "        model.add(LeakyReLU())\n",
    "        if 0 < dp < 1:\n",
    "            model.add(Dropout(dp))\n",
    "        \n",
    "        while config:\n",
    "            n, dp = config.pop(0)\n",
    "            model.add(Dense(n, kernel_initializer='uniform'))\n",
    "            model.add(LeakyReLU())\n",
    "            if 0 < dp < 1:\n",
    "                model.add(Dropout(dp))\n",
    "\n",
    "\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        opt = Adamax(lr=learn_rate)\n",
    "\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, callbacks=[]):\n",
    "        process_X = X.values if hasattr(X, 'iloc') else X\n",
    "        process_y = y\n",
    "        return self.model.fit(process_X, process_y, batch_size=self.batch_size,\n",
    "                       epochs=self.epochs, verbose=self.verbose,\n",
    "                       sample_weight=sample_weight,\n",
    "                       callbacks=callbacks,\n",
    "                       validation_split=self.validation_split,\n",
    "                       shuffle=True)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        process_x = X.values if hasattr(X, 'iloc') else X\n",
    "        result  = self.model.predict(process_x)\n",
    "        classone_probs = result\n",
    "        classzero_probs = 1.0 - classone_probs\n",
    "        return np.hstack((classzero_probs, classone_probs))\n",
    "#         return result\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_columns = [\n",
    "\"gender\",\n",
    "\"height\",\n",
    "\"weight\",\n",
    "\"ap_hi\",\n",
    "\"ap_lo\",\n",
    "\"cholesterol\",\n",
    "# \"gluc\",\n",
    "# \"active_fair\",\n",
    "\"smoke_restored\",\n",
    "\"alco_restored\",\n",
    "\"active_restored\",\n",
    "\"height_mul_log_gluc\",\n",
    "\"BMI\",\n",
    "\"age_group\",\n",
    "\"cholesterol_div_log_gluc\",\n",
    "\"gluc_mul_log_age\",\n",
    "]\n",
    "\n",
    "X1 = X_train[use_columns]\n",
    "X2 = X_test[use_columns]\n",
    "\n",
    "X = pd.concat((X1,X2), axis=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X1 = pd.DataFrame(scaler.transform(X1)) #.values\n",
    "X2 = pd.DataFrame(scaler.transform(X2)) #.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 folds logloss:\n",
      "[0.5398176975716229, 0.53902177177050103, 0.54205365875576927, 0.53952215795429959, 0.53682056784376031, 0.54021127974049987, 0.5398021075327597, 0.53969405788531211, 0.54014786682364979, 0.54143110054802046]\n",
      "mean: 0.539852226643\n",
      "std: 0.00132566004865\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-dc5acda0a889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0mstratification_groups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m               \u001b[0mcreate_callback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m              )\n",
      "\u001b[0;32mE:\\Projects\\ML Boot Camp V\\utils.py\u001b[0m in \u001b[0;36mexecute_model\u001b[0;34m(estimator, X_train, y_train, X_test, model_name, n_folds, n_splits, create_callback, verbose, seed, stratification_groups)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxte\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxte\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0msplit_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-48d5abebd83b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, callbacks)\u001b[0m\n\u001b[1;32m     59\u001b[0m                        \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                        \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                        shuffle=True)\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\theano\\tensor\\blas.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[1;31m# The error raised by numpy has no shape information, we mean to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "{'batch_size': 512, 'choice': {'dropout2': 0.2, 'layers': 'two', 'units2': 64}, \n",
    " 'dropout1': 0.2, 'epochs': 100, 'learning_rate': 0.01, 'units1': 64}\n",
    "\n",
    "def create(x1, x2):\n",
    "    config = [(64,0.2), (64,0.2)]\n",
    "    return KerasModel(var_num=len(use_columns),\n",
    "                   epochs=200,\n",
    "                   learn_rate=0.001,\n",
    "                   config=config,\n",
    "                   batch_size=1024,\n",
    "                   verbose=0,\n",
    "                   validation_split=0.0)\n",
    "utils.execute_model(None,\n",
    "              X1,\n",
    "              y_train,\n",
    "              X2,\n",
    "              model_name=\"KERAS_1\",\n",
    "              n_splits=15,\n",
    "              n_folds=10,\n",
    "              stratification_groups=strat,\n",
    "              create_callback=create\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KERAS_1\n",
      "0.541188333484\t0.541405679164\t0.541188333484\t0.541405679164\n",
      "\n",
      "model1-\n",
      "0.537495498978\t0.537706445895\t0.53815759386\t0.538294889252\n",
      "\n",
      "model2-\n",
      "0.537771013645\t0.538051774932\t0.537698317632\t0.53784253395\n",
      "\n",
      "model3-\n",
      "0.538029709996\t0.538415276079\t0.53753730697\t0.53771354451\n",
      "\n",
      "model5-\n",
      "0.538296979367\t0.538547578947\t0.537508023582\t0.537696880375\n",
      "\n",
      "model1\n",
      "0.538080079502\t0.538009376104\t0.537479453883\t0.537609018688\n",
      "\n",
      "model3\n",
      "0.538702687693\t0.539402696417\t0.53741390216\t0.770362462535\n",
      "\n",
      "model1+\n",
      "0.537856175071\t0.538141755107\t0.537347025354\t0.544398539016\n",
      "\n",
      "model2+\n",
      "0.538247526491\t0.53857718903\t0.537341094639\t0.543130882008\n"
     ]
    }
   ],
   "source": [
    "models = ['KERAS_1', 'XGB_1','XGB_2hist','XGB_3hist','XGB_4','LGB_1','LGB_2',]\n",
    "result = utils.merge_models(models, method='mean')\n",
    "pd.DataFrame(result).to_csv('merged_models.csv', index=False, header=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "############################################################\n",
    "# 0.537557163108\t0.537699150119 = 0.5428822 # + keras\n",
    "# 0.537519393165\t0.537619764695 = 0.5432057 * new log features\n",
    "\n",
    "# 0.538126862768\t0.538047373071 = 0.5431843\n",
    "# 0.538084892954\t0.538027778903 = 0.5433475\n",
    "# 0.538157706723\t0.538186899005 = 0.5430039 # без стасо-колонок\n",
    "# 0.537450021945\t0.537849282831 = 0.5434434\n",
    "# 0.537513993512\t0.537749328355 = 0.5433418\n",
    "\n",
    "# 0.537790804547\t0.538014148853 = 0.5438901 # overfit full\n",
    "\n",
    "# 0.537368545033                   = 0.5428417\n",
    "# 0.537561506209                   = 0.5432193\n",
    "# 0.537449005194                   = 0.5428384\n",
    "\n",
    "\n",
    "# 0.537727687638\t0.537773366433 = 0.5437636\n",
    "# 0.537662820586\t0.538506869394 = 0.5433681\n",
    "# 0.537639730851\t0.538322959718 = 0.5436416 # overfit due to smoke leak\n",
    "# 0.537723242359\t0.538418956272 = 0.5433819\n",
    "# 0.537697918691\t0.538454608940 = 0.5435035\n",
    "# 0.537797383673\t0.538468964022 = 0.5433098\n",
    "# 0.537998452494\t0.538697384187 = 0.5433633\n",
    "# 0.538141859286\t0.538727942758 = 0.5434983\n",
    "\n",
    "\n",
    "#--------------\n",
    "# 0.5430039"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
